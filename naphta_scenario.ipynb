{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-12T16:59:39.978691Z",
     "start_time": "2026-02-12T16:59:39.955020Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:59:41.245217Z",
     "start_time": "2026-02-12T16:59:41.218808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------------------------\n",
    "# I/O config\n",
    "# ---------------------------\n",
    "CONFIG_PATH = Path(\"naphta_config.yaml\")\n",
    "\n",
    "with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    CFG = yaml.safe_load(f)\n",
    "\n",
    "YEAR_START = int(CFG[\"years\"][\"start\"])\n",
    "YEAR_END = int(CFG[\"years\"][\"end\"])\n",
    "YEARS = np.arange(YEAR_START, YEAR_END + 1)\n",
    "\n",
    "INPUT_CSV = Path(CFG[\"input\"][\"csv_path\"])\n",
    "BASE_YEAR = int(CFG[\"input\"][\"base_year\"])\n",
    "\n",
    "OUT_BASE = Path(CFG[\"output\"][\"base_dir\"])\n",
    "SCENARIO_DIRS = {k: OUT_BASE / v for k, v in CFG[\"output\"][\"scenario_dirs\"].items()}\n",
    "\n",
    "CONV = CFG[\"conversion\"]\n",
    "E_PER_N = float(CONV[\"electricity_per_naphta\"])\n",
    "CH4_PER_N = float(CONV[\"ch4_per_naphta\"])\n",
    "H2_PER_N = float(CONV[\"h2_per_naphta\"])\n",
    "\n",
    "# Keep only real scenarios (avoid accidental keys like 'structural_decline')\n",
    "SC_PARAMS = {\n",
    "    k: v for k, v in CFG[\"scenarios\"].items()\n",
    "    if k in SCENARIO_DIRS\n",
    "}\n"
   ],
   "id": "9a52ed06bcd178af",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:59:42.317419Z",
     "start_time": "2026-02-12T16:59:42.298695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Helpers (robust & simple)\n",
    "# ---------------------------\n",
    "def read_naphta_raw(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # tolère un fichier sans header\n",
    "    if not {\"country\", \"demand_naphta\"}.issubset(df.columns):\n",
    "        df = pd.read_csv(path, header=None, names=[\"country\", \"demand_naphta\"])\n",
    "\n",
    "    df[\"country\"] = df[\"country\"].astype(str).str.strip().str.upper()\n",
    "    df[\"demand_naphta\"] = pd.to_numeric(df[\"demand_naphta\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"demand_naphta\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def assert_non_negative(df: pd.DataFrame, cols: list[str]) -> None:\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if not cols:\n",
    "        return\n",
    "    if (df[cols] < -1e-9).any(axis=None):\n",
    "        raise ValueError(\"Valeurs négatives détectées:\\n\" + str(df[cols].min()))\n",
    "\n",
    "\n",
    "def check_coverage(df: pd.DataFrame, y0: int, y1: int) -> None:\n",
    "    for c, g in df.groupby([\"country\", \"scenario\"]):\n",
    "        ys = np.sort(g[\"year\"].unique())\n",
    "        expected_n = (y1 - y0 + 1)\n",
    "        if ys[0] != y0 or ys[-1] != y1 or len(ys) != expected_n:\n",
    "            raise ValueError(\n",
    "                f\"Couverture années KO pour {c}: {ys[0]}..{ys[-1]} n={len(ys)} (attendu {expected_n}).\"\n",
    "            )\n",
    "\n",
    "\n",
    "def yoy_factor_series(years: np.ndarray, yoy_blocks: list[dict]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Construit une trajectoire multiplicative F(t) avec F(base_year)=1,\n",
    "    et pour chaque année t>base_year : F(t)=F(t-1)*f_yoy(t)\n",
    "    \"\"\"\n",
    "    f_yoy = np.ones_like(years, dtype=float)\n",
    "    for b in (yoy_blocks or []):\n",
    "        y0 = int(b[\"from\"])\n",
    "        y1 = int(b[\"to\"])\n",
    "        fac = float(b[\"factor\"])\n",
    "        mask = (years >= y0) & (years <= y1)\n",
    "        f_yoy[mask] = fac\n",
    "\n",
    "    # cumprod à partir de BASE_YEAR (inclu)\n",
    "    out = np.ones_like(years, dtype=float)\n",
    "    for i in range(1, len(years)):\n",
    "        out[i] = out[i - 1] * f_yoy[i]\n",
    "    return out\n",
    "\n",
    "\n",
    "def plateau_level_series(years: np.ndarray, plateaus: list[dict], key: str, default: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Série en plateaux : pour chaque bloc {from,to, <key>:val}, on affecte val.\n",
    "    \"\"\"\n",
    "    out = np.full_like(years, float(default), dtype=float)\n",
    "    for b in (plateaus or []):\n",
    "        y0 = int(b[\"from\"])\n",
    "        y1 = int(b[\"to\"])\n",
    "        val = float(b[key])\n",
    "        out[(years >= y0) & (years <= y1)] = val\n",
    "    return out\n",
    "\n",
    "def structural_factor_series(years: np.ndarray, base_year: int, sd: dict | None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Retourne un facteur multiplicatif f(t) tel que :\n",
    "    - f(base_year)=1\n",
    "    - pour t >= sd[\"start\"] : décroissance composée par sd[\"factor\"] (ex: 0.99)\n",
    "    - pour t < start : 1\n",
    "    \"\"\"\n",
    "    if not sd:\n",
    "        return np.ones_like(years, dtype=float)\n",
    "\n",
    "    fac = float(sd.get(\"factor\", 1.0))\n",
    "    start = int(sd.get(\"start\", base_year))\n",
    "\n",
    "    if fac <= 0.0 or fac > 1.0:\n",
    "        raise ValueError(\"structural_decline.factor doit être dans (0,1].\")\n",
    "\n",
    "    # Nombre d'années de décroissance appliquées\n",
    "    n = np.clip(years - start, 0, None).astype(int)\n",
    "    return np.power(fac, n)\n",
    "\n",
    "def build_scenario(tech_scenario: str, base_2019_by_country: dict[str, float], p: dict) -> pd.DataFrame:\n",
    "    yoy = yoy_factor_series(YEARS, p.get(\"yoy_factors\", []))\n",
    "\n",
    "    # plateau multiplicatif additionnel (intermediary)\n",
    "    plateaus = p.get(\"demand_plateaus\", [])\n",
    "    plateau_level = plateau_level_series(YEARS, plateaus, key=\"level\", default=1.0) if plateaus else np.ones_like(YEARS, float)\n",
    "\n",
    "    demand_factor = yoy * plateau_level\n",
    "\n",
    "    sd = p.get(\"structural_decline\", None)\n",
    "    struct_factor = structural_factor_series(YEARS, base_year=BASE_YEAR, sd=sd)\n",
    "\n",
    "    # import share (import scenario uniquement)\n",
    "    import_plateaus = p.get(\"import_plateaus\", [])\n",
    "    if import_plateaus:\n",
    "        import_share = plateau_level_series(YEARS, import_plateaus, key=\"import_share\", default=0.0)\n",
    "        import_share = np.clip(import_share, 0.0, 1.0)\n",
    "    else:\n",
    "        import_share = np.zeros_like(YEARS, dtype=float)\n",
    "\n",
    "    out = []\n",
    "    for country, base0 in base_2019_by_country.items():\n",
    "        naphta_total = base0 * demand_factor\n",
    "        naphta_total = np.clip(naphta_total, 0.0, None)\n",
    "\n",
    "        # import \"de base\" (import scenario) sinon 0\n",
    "        naphta_imported_base = naphta_total * import_share\n",
    "        naphta_imported_base = np.clip(naphta_imported_base, 0.0, naphta_total)\n",
    "\n",
    "        naphta_domestic_base = naphta_total - naphta_imported_base\n",
    "        naphta_domestic_base = np.clip(naphta_domestic_base, 0.0, naphta_total)\n",
    "\n",
    "\n",
    "        # ---- structural decline (YAML) : appliqué au domestique, compensé par import ----\n",
    "        if sd is not None:\n",
    "            naphta_domestic = naphta_domestic_base * struct_factor\n",
    "            naphta_domestic = np.clip(naphta_domestic, 0.0, naphta_total)\n",
    "\n",
    "            # compensation import = total - domestic (comptabilité parfaite)\n",
    "            naphta_imported = naphta_total - naphta_domestic\n",
    "            naphta_imported = np.clip(naphta_imported, 0.0, naphta_total)\n",
    "        else:\n",
    "            naphta_domestic = naphta_domestic_base\n",
    "            naphta_imported = naphta_imported_base\n",
    "        # import_share effectif (incluant compensation structurelle)\n",
    "        import_share_eff = np.zeros_like(naphta_total)\n",
    "\n",
    "        mask = naphta_total > 0\n",
    "        import_share_eff[mask] = naphta_imported[mask] / naphta_total[mask]\n",
    "        # Conversion -> intrants (appliquée seulement au domestique)\n",
    "        elec = naphta_domestic * E_PER_N\n",
    "        ch4 = naphta_domestic * CH4_PER_N\n",
    "        h2 = naphta_domestic * H2_PER_N\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"country\": country,\n",
    "            \"scenario\": tech_scenario,\n",
    "            \"year\": YEARS,\n",
    "\n",
    "            \"naphta_total\": naphta_total,\n",
    "            \"naphta_domestic\": naphta_domestic,\n",
    "            \"naphta_imported\": naphta_imported,\n",
    "\n",
    "            \"electricity_demand_from_naphta\": elec,\n",
    "            \"ch4_demand_from_naphta\": ch4,\n",
    "            \"h2_demand_from_naphta\": h2,\n",
    "\n",
    "            # audit\n",
    "            \"demand_factor\": demand_factor,\n",
    "            \"import_share\": import_share_eff,\n",
    "        })\n",
    "        out.append(df)\n",
    "\n",
    "    df_all = pd.concat(out, ignore_index=True)\n",
    "\n",
    "    # contrôles\n",
    "    assert_non_negative(df_all, [\n",
    "        \"naphta_total\", \"naphta_domestic\", \"naphta_imported\",\n",
    "        \"electricity_demand_from_naphta\", \"ch4_demand_from_naphta\", \"h2_demand_from_naphta\",\n",
    "        \"demand_factor\", \"import_share\",\n",
    "    ])\n",
    "\n",
    "    err = (df_all[\"naphta_total\"] - (df_all[\"naphta_domestic\"] + df_all[\"naphta_imported\"])).abs().max()\n",
    "    if err > 1e-6:\n",
    "        raise ValueError(f\"Incohérence: total != domestic + import (max err={err}).\")\n",
    "\n",
    "    check_coverage(df_all, YEAR_START, YEAR_END)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def write_outputs(tech_scenario: str, df: pd.DataFrame) -> None:\n",
    "    out_dir = SCENARIO_DIRS[tech_scenario]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_dir / \"demand_naphta.csv\", index=False)\n",
    "\n"
   ],
   "id": "a64087550c397ad9",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:59:46.015534Z",
     "start_time": "2026-02-12T16:59:45.947355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "df_raw = read_naphta_raw(INPUT_CSV)\n",
    "\n",
    "# ancre 2019 : uniquement consommation 2019, une ligne par country\n",
    "# (pas de DE/GA ici, c'est voulu et cohérent avec votre instruction)\n",
    "base = (\n",
    "    df_raw.groupby(\"country\", as_index=False)[\"demand_naphta\"]\n",
    "          .sum()\n",
    ")\n",
    "\n",
    "base_2019_by_country = dict(zip(base[\"country\"], base[\"demand_naphta\"]))\n",
    "\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "all_outputs: dict[str, pd.DataFrame] = {}\n",
    "for tech_scenario, params in SC_PARAMS.items():\n",
    "    df_scn = build_scenario(tech_scenario, base_2019_by_country, params)\n",
    "    write_outputs(tech_scenario, df_scn)\n",
    "    all_outputs[tech_scenario] = df_scn\n",
    "\n",
    "with (OUT_BASE / \"config_effective.yaml\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(CFG, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"OK: scénarios naphta générés dans\", OUT_BASE)"
   ],
   "id": "1cff8dddc40c249d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: scénarios naphta générés dans /Users/simonbrigode/Desktop/tp_pommes_kraft/data_country/industry/pommes-h2-network/data-pommes/scenarios-naphta\n"
     ]
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
